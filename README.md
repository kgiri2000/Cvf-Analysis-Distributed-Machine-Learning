# Distributed Machine Learning for Consistency-Violation Analysis
### Single-GPU and Multi-Worker TensorFlow Implementation

> **Updated version:** `v2/` (previous version available in `v1/`)  
> **Publication:** [arXiv:2506.02002](https://arxiv.org/abs/2506.02002)

This repository implements a **distributed TensorFlow** pipeline for analyzing *Consistency Violation Faults (CVFs)* in Dijkstra’s Token Ring and related self-stabilizing algorithms. The model predicts the **average path count** for nodes (with states in `{0,1,2}`) to return to the invariant state.

It supports:
- **Single-GPU training**
- **Multi-node distributed training** via `tf.distribute.MultiWorkerMirroredStrategy`

---

## Dataset

Datasets are generated by [`v2/src/dijkstra.py`](./v2/src/dijkstra.py).

Each data sample represents a node configuration in **Dijkstra’s Token Ring** topology and consists of:
- **Feature vector:** `max_prediction + 1` values  
- **Label:** Actual path length (rank) to reach the invariant state  

### Feature Composition
| Segment | Description |Type|
|----------|--------------|---|
| `[0 ... (max_prediction - 1)]` | Node states (`0`, `1`, or `2` or placeholders) | features
| [`current_node_number`] | Topology metadata / node ID placeholders | features
| `Average_path_length` | Actual path length (rank) | label|

---

### Example (Predicting up to 12 nodes)
```python
state_of_node = 0 or 1 or 2
feature = [0, 1, 2, 0, 0, 0, 1, 2, 1, 1, 2, -1, -1, 8]  # last two are placeholders
label = [50]  # actual path length (rank)

```
---
## Project Layout

| Path | Description |
|------|--------------|
| `v2/src/` | Core training modules |
| ├─ `trainer_distributed.py` | Distributed training logic |
| ├─ `trainer_single_gpu.py` | Single GPU training |
| `v2/datasets/` | Input CSV datasets |
| `v2/logs/` | Output logs and checkpoints |
| `v2/generatedataset.py` | Generates data from Dijkstra’s token ring algorithm |
| `v2/main.py` | Main entry point |
| `v2/launch_training.sh` | Script to launch training |

---

## Hardware

| Component | Specification |
|------------|---------------|
| CPU | Intel Core i7-13700K |
| GPU | NVIDIA GeForce RTX 4090 |
| OS | Ubuntu 24.04 LTS |

---

## How to Run?

### A. Local Single-GPU Training

#### Generate Dataset
```bash
python3 generatedataset.py
```

This will create two datasets using Dijkstra's self-stabilizing algorithm:

1. **Training dataset** – Generated from `generatedataset(starting_node, max_node, max_pred_node)`
2. **Prediction dataset** – Generated from `generatedataset(max_prediction_node, node_to_predict)`

> **Note:** Parameters for both datasets can be configured in `generatedataset.py`


---
### Training
```bash
bash launch_training.sh
```

**Options:**
- **Training mode:** Single-node GPU Training (option 1)
- **Dataset path:** Path to your training data
- **Epochs:** Number of training epochs
- **Batch size:** Training batch size
- **Learning rate:** Model learning rate
- **Input size:** Input dimension size

**Output:**
- Loss and MAE curves → `/plots`
- Model and training history → `/models`
- Training logs → `/logs`
- Predicted path counts → `datasets/`
- Actual vs predicted plots → `/plots`

---

### Results for Single-Node Training

*(Add your results here)*

---

### B. Distributed Machine Learning via `tf.distribute.MultiWorkerMirroredStrategy`
```bash
bash launch_training.sh
```

> **Note:** Nodes can be configured in `cluster.env`  
> **Current machines:** Ubuntu 24.04

**Options:**
- **Training mode:** Multi-worker distributed training (option 2)
- All other options are similar to single-node training

---

### Results for Multi-Worker Distributed Training

*(Add your results here)*



